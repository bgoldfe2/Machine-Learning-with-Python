{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f40ed0c0-bf74-4e54-bf6b-06f8a050fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://medium.com/@bedigunjit/simple-guide-to-text-classification-nlp-using-svm-and-naive-bayes-with-python-421db3a72d34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5639f2f-9dee-47df-b310-70ff683cb40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38746</td>\n",
       "      <td>#trumprussia sean spicer is a blithering idiot...</td>\n",
       "      <td>Others</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47265</td>\n",
       "      <td>If you call yourself a Christian yet you suppo...</td>\n",
       "      <td>Religion</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36632</td>\n",
       "      <td>Small red lights in dark rooms.</td>\n",
       "      <td>Others</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29064</td>\n",
       "      <td>If u find yourself pouting that no male report...</td>\n",
       "      <td>Notcb</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33884</td>\n",
       "      <td>Messi carried these retards to three consecuti...</td>\n",
       "      <td>Others</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26525</td>\n",
       "      <td>#MKR France Vs Ireland Vs Paleo Pete...LETS RU...</td>\n",
       "      <td>Notcb</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41797</td>\n",
       "      <td>Today's front page of the New York Times. A fu...</td>\n",
       "      <td>Religion</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33241</td>\n",
       "      <td>too bad I'm a size 11 men and got basketball t...</td>\n",
       "      <td>Others</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11082</td>\n",
       "      <td>@_sarahjessiee @Khalil_Perry fuck that dumb as...</td>\n",
       "      <td>Ethnicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44179</td>\n",
       "      <td>That Christian woman did the right thing</td>\n",
       "      <td>Religion</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text      label  \\\n",
       "0       38746  #trumprussia sean spicer is a blithering idiot...     Others   \n",
       "1       47265  If you call yourself a Christian yet you suppo...   Religion   \n",
       "2       36632                    Small red lights in dark rooms.     Others   \n",
       "3       29064  If u find yourself pouting that no male report...      Notcb   \n",
       "4       33884  Messi carried these retards to three consecuti...     Others   \n",
       "5       26525  #MKR France Vs Ireland Vs Paleo Pete...LETS RU...      Notcb   \n",
       "6       41797  Today's front page of the New York Times. A fu...   Religion   \n",
       "7       33241  too bad I'm a size 11 men and got basketball t...     Others   \n",
       "8       11082  @_sarahjessiee @Khalil_Perry fuck that dumb as...  Ethnicity   \n",
       "9       44179           That Christian woman did the right thing   Religion   \n",
       "\n",
       "   target  \n",
       "0       4  \n",
       "1       5  \n",
       "2       4  \n",
       "3       3  \n",
       "4       4  \n",
       "5       3  \n",
       "6       5  \n",
       "7       4  \n",
       "8       1  \n",
       "9       5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "#Set Random seed\n",
    "np.random.seed(500)\n",
    "\n",
    "# Add the Data using pandas\n",
    "#Corpus = pd.read_csv(r\"./data/corpus.csv\",encoding='latin-1')\n",
    "Corpus = pd.read_csv(r\"./Dataset/SixClass/train.csv\",encoding='latin-1')\n",
    "Corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4488aa0f-c7b5-4806-ba66-f5d6972f186f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - 1: Data Pre-processing - This will help in getting better results through the classification algorithms\n",
    "\n",
    "# Step - 1a : Remove blank rows if any.\n",
    "Corpus['text'].dropna(inplace=True)\n",
    "\n",
    "# Step - 1b : Change all the text to lower case. This is required as python interprets 'dog' and 'DOG' differently\n",
    "Corpus['text'] = [entry.lower() for entry in Corpus['text']]\n",
    "\n",
    "# Step - 1c : Tokenization : In this each entry in the corpus will be broken into set of words\n",
    "Corpus['text']= [word_tokenize(entry) for entry in Corpus['text']]\n",
    "\n",
    "# Step - 1d : Remove Stop words, Non-Numeric and perfom Word Stemming/Lemmenting.\n",
    "\n",
    "# WordNetLemmatizer requires Pos tags to understand if the word is noun or verb or adjective etc. By default it is set to Noun\n",
    "tag_map = defaultdict(lambda : wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "\n",
    "for index,entry in enumerate(Corpus['text']):\n",
    "    # Declaring Empty List to store the words that follow the rules for this step\n",
    "    Final_words = []\n",
    "    # Initializing WordNetLemmatizer()\n",
    "    word_Lemmatized = WordNetLemmatizer()\n",
    "    # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "    for word, tag in pos_tag(entry):\n",
    "        # Below condition is to check for Stop words and consider only alphabets\n",
    "        if word not in stopwords.words('english') and word.isalpha():\n",
    "            word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "            Final_words.append(word_Final)\n",
    "    # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "    Corpus.loc[index,'text_final'] = str(Final_words)\n",
    "\n",
    "#print(Corpus['text_final'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6fb77f-64e5-4382-8e8f-7e677ba44762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - 2: Split the model into Train and Test Data set\n",
    "Train_X, Test_X, Train_Y, Test_Y = model_selection.train_test_split(Corpus['text_final'],Corpus['label'],test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e495c6-0a11-4407-8ea7-3e7791bc2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - 3: Label encode the target variable  - This is done to transform Categorical data of string type in the data set into numerical values\n",
    "Encoder = LabelEncoder()\n",
    "Train_Y = Encoder.fit_transform(Train_Y)\n",
    "Test_Y = Encoder.fit_transform(Test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d533906c-71ae-4081-9f3e-17e4ce414fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step - 4: Vectorize the words by using TF-IDF Vectorizer - This is done to find how important a word in document is in comaprison to the corpus\n",
    "Tfidf_vect = TfidfVectorizer(max_features=5000)\n",
    "Tfidf_vect.fit(Corpus['text_final'])\n",
    "\n",
    "Train_X_Tfidf = Tfidf_vect.transform(Train_X)\n",
    "Test_X_Tfidf = Tfidf_vect.transform(Test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5dbf90d-a6f3-4ebe-b635-fc0889af5b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  77.73378362641202\n",
      "Naive Bayes F1 Score (macro avg) ->  76.3315394089895\n",
      "Naive Bayes F1 Score (multi-class) ->  [96.27009646 96.94454923 86.56826568 56.05431912 65.75949367 94.39834025]\n",
      "\n",
      "SVM Accuracy Score ->  82.70641667637126\n",
      "Logistic Regression F1 Score (macro avg) ->  76.3315394089895\n",
      "Logistic Regreassion F1 Score (multi-class) ->  [96.27009646 96.94454923 86.56826568 56.05431912 65.75949367 94.39834025]\n"
     ]
    }
   ],
   "source": [
    "# Step - 5: Now we can run different algorithms to classify out data check for accuracy\n",
    "\n",
    "# Classifier - Algorithm - Naive Bayes\n",
    "# fit the training dataset on the classifier\n",
    "Naive = naive_bayes.MultinomialNB()\n",
    "Naive.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_NB = Naive.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, Test_Y)*100)\n",
    "print(\"Naive Bayes F1 Score (macro avg) -> \",f1_score(Test_Y, predictions_NB, average='macro')*100)\n",
    "print(\"Naive Bayes F1 Score (multi-class) -> \",f1_score(Test_Y, predictions_SVM, average=None)*100)\n",
    "\n",
    "\n",
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "SVM.fit(Train_X_Tfidf,Train_Y)\n",
    "\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM = SVM.predict(Test_X_Tfidf)\n",
    "\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"\\nSVM Accuracy Score -> \",accuracy_score(predictions_SVM, Test_Y)*100)\n",
    "print(\"Logistic Regression F1 Score (macro avg) -> \",f1_score(Test_Y, predictions_NB, average='macro')*100)\n",
    "print(\"Logistic Regreassion F1 Score (multi-class) -> \",f1_score(Test_Y, predictions_SVM, average=None)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ccd937-1fec-4bd1-920c-87a87ca6c698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86      1546\n",
      "           1       0.81      0.92      0.86      1329\n",
      "           2       0.84      0.81      0.83      1406\n",
      "           3       0.67      0.43      0.53      1433\n",
      "           4       0.64      0.56      0.60      1411\n",
      "           5       0.85      0.96      0.90      1462\n",
      "\n",
      "    accuracy                           0.78      8587\n",
      "   macro avg       0.77      0.78      0.76      8587\n",
      "weighted avg       0.77      0.78      0.76      8587\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1494   12    5   14   13    8]\n",
      " [  33 1226    7    7   23   33]\n",
      " [  27   48 1138   96   71   26]\n",
      " [ 174   92   89  622  328  128]\n",
      " [ 178  117   99  170  789   58]\n",
      " [  10   11    9   21    5 1406]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y,predictions_NB))\n",
    "print('Confusion Matrix:\\n',confusion_matrix(Test_Y, predictions_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87eee145-9f05-4354-8502-789b59944e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1546\n",
      "           1       0.97      0.97      0.97      1329\n",
      "           2       0.90      0.83      0.87      1406\n",
      "           3       0.61      0.52      0.56      1433\n",
      "           4       0.59      0.74      0.66      1411\n",
      "           5       0.95      0.93      0.94      1462\n",
      "\n",
      "    accuracy                           0.83      8587\n",
      "   macro avg       0.83      0.83      0.83      8587\n",
      "weighted avg       0.83      0.83      0.83      8587\n",
      "\n",
      "Confusion Matrix:\n",
      " [[1497    2    5   19   23    0]\n",
      " [   3 1285    7    8   25    1]\n",
      " [   3    5 1173  103  118    4]\n",
      " [  52   13   53  743  517   55]\n",
      " [   9   11   63  284 1039    5]\n",
      " [   0    6    3   61   27 1365]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Test_Y,predictions_SVM))\n",
    "print('Confusion Matrix:\\n',confusion_matrix(Test_Y, predictions_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c9e48-379f-4041-8649-083a6dc999cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss-final",
   "language": "python",
   "name": "diss-final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
